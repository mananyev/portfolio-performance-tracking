id: all_tickers_names
namespace: ppt-project
description: |
  Working version for Kestra 0.22.2 (GCP).
  The main flow, orchestrating all the steps.
  Once all KVs are set (by the `set_gcp_kv` flow), it is good to go.


concurrency:
  limit: 1


inputs:
  - id: whole_history
    type: BOOLEAN
    defaults: false
    description: |
      Whether to pull all available historical prices, ignoring time periods.
  - id: reload_tickers_list
    type: BOOLEAN
    defaults: false
    description: |
      Whether to reload the constituents of the indices.
  - id: reload_portfolio
    type: BOOLEAN
    defaults: false
    description: |
      Whether to reload the portfolio positions.
  - id: initialize
    type: BOOLEAN
    defaults: false
    description: |
      Whether it is the first run: determines whether
      all the required tables are created, whether scripts
      and dbt models need to be pulled from GitHub.


variables:
  all_tickers_table: "{{kv('all_tickers_table')}}"
  all_tickers_prices_table: "{{kv('all_tickers_prices_table')}}"


tasks:
  - id: first_time_init
    type: io.kestra.plugin.core.flow.If
    description: |
      Checks if all components need to be set:
      - main tables created,
      - scripts pulled.
    condition: "{{inputs.initialize == true}}"
    then:
      - id: sync_scripts
        type: io.kestra.plugin.git.SyncNamespaceFiles
        description: |
          Downloads Python scripts from the GitHub repo.
        url: https://github.com/mananyev/portfolio-performance-tracking
        branch: "{{kv('BRANCH')}}"
        namespace: "{{flow.namespace}}"
        gitDirectory: src/kestra/scripts
        dryRun: false

      - id: create_all_tickers_prices_table
        type: io.kestra.plugin.gcp.bigquery.Query
        description: |
          Creates the main table with all tickers and their prices.
        sql: |
          CREATE TABLE IF NOT EXISTS `{{render(vars.all_tickers_prices_table)}}`
          (
              unique_row_id BYTES OPTIONS (description = 'A unique identifier for the ticker-date, generated by hashing ticker and date.')
              , ticker STRING OPTIONS (description = 'The ticker symbol from Yahoo! Finance.')
              , date DATE OPTIONS (description = 'The date to which financial data corresponds.')
              , open FLOAT64 OPTIONS (description = 'Daily Open price.')
              , high FLOAT64 OPTIONS (description = 'Daily High price.')
              , low FLOAT64 OPTIONS (description = 'Daily Low price')
              , close FLOAT64 OPTIONS (description = 'Daily Close price.')
              , volume INTEGER OPTIONS (description = 'Daily Traded volume.')
              , dividends FLOAT64 OPTIONS (description = 'Daily Dividends paid.')
              , stock_splits FLOAT64 OPTIONS (description = 'Daily Stock splits.')
          )
          PARTITION BY DATE_TRUNC(date, MONTH)
          CLUSTER BY ticker;

      - id: create_all_tickers_table
        type: io.kestra.plugin.gcp.bigquery.Query
        description: |
          Creates the table, containing all tickers description:
          - company name,
          - region,
          - sector,
          - industry,
          - exchange, where traded.
        sql: |
          CREATE TABLE IF NOT EXISTS `{{render(vars.all_tickers_table)}}`
          (
              ticker STRING OPTIONS (description = 'The ticker symbol from Yahoo! Finance.')
              , company STRING OPTIONS (description = 'Company name.')
              , region STRING OPTIONS (description = 'Company region.')
              , sector STRING OPTIONS (description = 'Company sector.')
              , industry STRING OPTIONS (description = 'Company industry.')
              , exchange STRING OPTIONS (description = 'Exchange where the ticker is traded.')
          );

  - id: check_reload_tickers_list
    type: io.kestra.plugin.core.flow.If
    description: |
      Checks if one needs to reload all tickers data.
    condition: "{{inputs.reload_tickers_list == true}}"
    then:
      - id: clear_all_tickers_list
        type: io.kestra.plugin.core.kv.Delete
        description: |
          Drops KV with the list of all tickers in the database.
        key: all_tickers
        errorOnMissing: false

      - id: set_all_tickers_kv
        type: io.kestra.plugin.core.kv.Set
        description: |
          Sets KV with the list of all tickers in the database
          to exist but contain nothing.
        key: all_tickers
        kvType: STRING
        value: ""

      - id: get_constituents_urls
        type: io.kestra.plugin.core.http.Download
        description: |
          Downloads JSON file with links to indices' constituents.
        uri: "{{kv('CONSTITUENTS_LINKS')}}"

      - id: split_json
        type: io.kestra.plugin.scripts.python.Script
        description: |
          Extracts links and region data from the downloaded JSON.
          Saves the output as a CSV.
        containerImage: ghcr.io/kestra-io/pydata:latest  # Pre-built image with Pandas
        inputFiles:
          constituents.json: "{{ outputs.get_constituents_urls.uri }}"
        outputFiles:
          - "constituents_links.csv"
        script: |
          import json
          import pandas as pd
          from kestra import Kestra

          with open("constituents.json", 'r') as file:
              constituents_data = json.load(file)

          constituents_df = pd.DataFrame(constituents_data).T
          constituents_df.index.name = 'region'
          constituents_df.to_csv("constituents_links.csv", index=True)

      - id: upload_to_gcs
        type: io.kestra.plugin.gcp.gcs.Upload
        description: |
          Uploads the parsed JSON (CSV file) to the GS bucket.
        from: "{{outputs.split_json.outputFiles['constituents_links.csv']}}"
        to: "gs://{{kv('GCP_BUCKET_NAME')}}/index_constituents_and_links.csv"

      - id: read_regions_csv
        type: io.kestra.plugin.serdes.csv.CsvToIon
        description: |
          Splits the regions / indices into rows to be used in the loop below.
        from: "{{outputs.split_json.outputFiles['constituents_links.csv']}}"

      - id: loop_over_regions
        description: |
          Downloads and saves historic prices in region batches
          (with `period='max'` argument).
          Uses a subflow `backfill_parent_flow`.
        type: io.kestra.plugin.core.flow.ForEachItem
        items: "{{outputs.read_regions_csv.uri}}"
        namespace: ppt-project
        flowId: backfill_parent_flow
        inputs:
          region_json: "{{taskrun.items}}"
          reload_tickers_list: "{{inputs.reload_tickers_list}}"
          backfill_all: "{{inputs.whole_history}}"
          data_from: "{{trigger.previous ?? (execution.startDate | dateAdd(-1, 'DAYS'))}}"
          data_to: "{{trigger.date ?? (execution.startDate | dateAdd(-1, 'DAYS'))}}"

    else:
      - id: log_ticker_list_in_KV
        type: io.kestra.plugin.core.log.Log
        message: |
          All tickers are already in KV Store.

    finally:
      - id: check_reload_portfolio
        type: io.kestra.plugin.core.flow.If
        description: |
          Checks if portfolio positions have to be reloaded.
        condition: "{{inputs.reload_portfolio == true}}"
        then:
          - id: clear_portfolio
            type: io.kestra.plugin.core.kv.Delete
            description: |
              Drops KV with the list of unique portfolio tickers.
            key: portfolio_tickers
            errorOnMissing: false

          - id: set_portfolio_tickers_kv
            type: io.kestra.plugin.core.kv.Set
            description: |
              Sets KV with the list of unique portfolio tickers
              to exist but contain nothing.
            key: portfolio_tickers
            kvType: STRING
            value: ""

        else:
          - id: log_portfolio_tickets
            type: io.kestra.plugin.core.log.Log
            message: |
              Portfolio tickers are already in KV Store.
        
        finally:
          - id: synchronize_portfolio
            description: |
              Checks if tickers used in portfolio are in the data base.
              Downloads the missing tickers and
              updates the list of all tickers.
              Uses a subflow `subflow_synchronize_portfolio`.
            type: io.kestra.plugin.core.flow.Subflow
            namespace: ppt-project
            flowId: subflow_synchronize_portfolio
            inputs:
              backfill_all: "{{inputs.whole_history}}"
              data_from: "{{trigger.previous ?? (execution.startDate | dateAdd(-1, 'DAYS'))}}"
              data_to: "{{trigger.date ?? (execution.startDate | dateAdd(-1, 'DAYS'))}}"

      - id: read_all_tickers_list
        type: io.kestra.plugin.core.kv.Get
        description: |
          Loads (updated) tickers in the database.
        key: all_tickers

      - id: no_update_after_backfill
        type: io.kestra.plugin.core.flow.If
        description: |
          Checks if backfill already happened
          (after the first run or after reloading all tickers).
        condition: "{{inputs.reload_tickers_list == true}}"
        then:
          - id: no_update_needed
            type: io.kestra.plugin.core.log.Log
            message: |
              All tickers were just back-filled.
        else:
          - id: subflow_update_all_tickers_prices
            type: io.kestra.plugin.core.flow.Subflow
            description: |
              Updates the data for all tickers
              with the latest trading day information.
            namespace: ppt-project
            flowId: subflow_ticker_history
            inputs:
              region: all
              tickers: "{{outputs.read_all_tickers_list.value}}"
              backfill_all: false
              data_from: "{{trigger.previous ?? (execution.startDate | dateAdd(-1, 'DAYS'))}}"
              data_to: "{{trigger.date ?? (execution.startDate | dateAdd(-1, 'DAYS'))}}"

      - id: run_dbt
        description: |
          Runs the dbt: `dbt build` by default.
        type: io.kestra.plugin.core.flow.Subflow
        namespace: ppt-project
        flowId: bigquery_dbt
        inputs:
          first_dbt_run: "{{inputs.initialize}}"

      - id: purge_files
        type: io.kestra.plugin.core.storage.PurgeCurrentExecutionFiles
        description: To avoid cluttering your storage, we will remove the downloaded files

pluginDefaults:
  - type: io.kestra.plugin.gcp
    values:
      serviceAccount: "{{secret('GCP_SERVICE_ACCOUNT')}}"
      projectId: "{{kv('GCP_PROJECT_ID')}}"
      location: "{{kv('GCP_LOCATION')}}"
      bucket: "{{kv('GCP_BUCKET_NAME')}}"


# since we only need the data to be updated for up to previos working day
# we do not need updates past Saturday (Friday data updated), i.e. Sunday
# and on Monday (there is no Sunday updates).
# we also want to exclude public holidays (US in this case).
triggers:
  - id: on_workdays
    type: io.kestra.plugin.core.trigger.Schedule
    cron: "0 10 * * *"
    conditions:
      - type: io.kestra.plugin.core.condition.Not
        conditions:
          - type: io.kestra.plugin.core.condition.DayWeek
            dayOfWeek: "MONDAY"
          - type: io.kestra.plugin.core.condition.DayWeek
            dayOfWeek: "SUNDAY"
    stopAfter:
      - FAILED
    disabled: false
